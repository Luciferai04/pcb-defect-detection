{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with PCB Defect Detection\n",
    "\n",
    "This tutorial will walk you through the basics of using the PCB Defect Detection framework.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Loading and using pre-trained models\n",
    "2. Creating foundation model adapters\n",
    "3. Running inference on PCB images\n",
    "4. Understanding the results\n",
    "5. Training your own model\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Make sure you have installed the required dependencies:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our custom modules\n",
    "from enhanced_pcb_model import create_enhanced_model\n",
    "from core.foundation_adapter import create_foundation_adapter, set_reproducible_seed\n",
    "\n",
    "# Set reproducible seed for consistent results\n",
    "set_reproducible_seed(42)\n",
    "\n",
    "print(\"✓ All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Determine device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create and Load a Model\n",
    "\n",
    "Let's start by creating an enhanced PCB model with LoRA adaptation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced PCB model\n",
    "model, loss_fn = create_enhanced_model(\n",
    "    num_classes=5,\n",
    "    backbone='resnet50',\n",
    "    lora_rank=4\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Display model information\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "efficiency = 1.0 - (trainable_params / total_params)\n",
    "\n",
    "print(f\"Model created successfully!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Parameter efficiency: {efficiency:.4f} ({efficiency*100:.2f}% frozen)\")\n",
    "\n",
    "# Define class names\n",
    "class_names = ['normal', 'missing_component', 'solder_bridge', 'misalignment', 'short_circuit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Helper function to preprocess images\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess an image for inference\"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return transform(image).unsqueeze(0).to(device), image\n",
    "\n",
    "print(\"✓ Image preprocessing pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Synthetic Test Data\n",
    "\n",
    "Since we might not have actual PCB images, let's create some synthetic test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic PCB images for demonstration\n",
    "def create_synthetic_pcb_image(defect_type='normal', size=(224, 224)):\n",
    "    \"\"\"Create a synthetic PCB image with simulated defects\"\"\"\n",
    "    \n",
    "    # Base PCB (green background)\n",
    "    image = np.full((*size, 3), [0, 100, 0], dtype=np.uint8)\n",
    "    \n",
    "    # Add circuit traces (copper color)\n",
    "    for i in range(0, size[0], 20):\n",
    "        image[i:i+2, :] = [184, 115, 51]  # Copper color\n",
    "    \n",
    "    for j in range(0, size[1], 30):\n",
    "        image[:, j:j+2] = [184, 115, 51]  # Copper color\n",
    "    \n",
    "    # Add components (black rectangles)\n",
    "    component_positions = [(50, 50), (100, 100), (150, 150), (80, 170)]\n",
    "    \n",
    "    for x, y in component_positions:\n",
    "        if defect_type == 'missing_component' and (x, y) == component_positions[0]:\n",
    "            continue  # Skip first component to simulate missing\n",
    "        \n",
    "        # Draw component\n",
    "        image[y:y+15, x:x+25] = [20, 20, 20]  # Black component\n",
    "        \n",
    "        # Add solder bridge if needed\n",
    "        if defect_type == 'solder_bridge' and (x, y) == component_positions[1]:\n",
    "            image[y+15:y+25, x:x+25] = [200, 200, 200]  # Silver solder bridge\n",
    "    \n",
    "    # Add misalignment\n",
    "    if defect_type == 'misalignment':\n",
    "        x, y = component_positions[2]\n",
    "        image[y+5:y+20, x+10:x+35] = [20, 20, 20]  # Misaligned component\n",
    "    \n",
    "    # Add short circuit (red line)\n",
    "    if defect_type == 'short_circuit':\n",
    "        image[120:125, 60:140] = [255, 0, 0]  # Red short circuit\n",
    "    \n",
    "    return Image.fromarray(image)\n",
    "\n",
    "# Create sample images for each defect type\n",
    "sample_images = {}\n",
    "for defect_type in class_names:\n",
    "    sample_images[defect_type] = create_synthetic_pcb_image(defect_type)\n",
    "\n",
    "# Display the synthetic images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i, (defect_type, image) in enumerate(sample_images.items()):\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(defect_type.replace('_', ' ').title())\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Synthetic PCB images created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run Inference\n",
    "\n",
    "Now let's test our model on the synthetic images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_defect(image, model, transform, class_names, device):\n",
    "    \"\"\"Predict defect type from image\"\"\"\n",
    "    \n",
    "    # Preprocess image\n",
    "    if isinstance(image, Image.Image):\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    else:\n",
    "        image_tensor = image\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predicted_class_id = torch.argmax(probabilities, dim=1).item()\n",
    "        confidence = probabilities[0][predicted_class_id].item()\n",
    "    \n",
    "    return {\n",
    "        'predicted_class': class_names[predicted_class_id],\n",
    "        'class_id': predicted_class_id,\n",
    "        'confidence': confidence,\n",
    "        'probabilities': {class_names[i]: float(probabilities[0][i]) for i in range(len(class_names))}\n",
    "    }\n",
    "\n",
    "# Test on synthetic images\n",
    "results = {}\n",
    "for defect_type, image in sample_images.items():\n",
    "    result = predict_defect(image, model, transform, class_names, device)\n",
    "    results[defect_type] = result\n",
    "    \n",
    "    print(f\"\\n{defect_type.upper()} PCB:\")\n",
    "    print(f\"  Predicted: {result['predicted_class']} (confidence: {result['confidence']:.3f})\")\n",
    "    print(f\"  Top probabilities:\")\n",
    "    sorted_probs = sorted(result['probabilities'].items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    for class_name, prob in sorted_probs:\n",
    "        print(f\"    {class_name}: {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Results\n",
    "\n",
    "Let's create a comprehensive visualization of our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of predictions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "\n",
    "for i, (defect_type, image) in enumerate(sample_images.items()):\n",
    "    result = results[defect_type]\n",
    "    \n",
    "    # Display image\n",
    "    axes[0, i].imshow(image)\n",
    "    axes[0, i].set_title(f'Ground Truth: {defect_type.replace(\"_\", \" \").title()}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Display prediction probabilities\n",
    "    probs = list(result['probabilities'].values())\n",
    "    colors = ['green' if class_names[j] == result['predicted_class'] else 'lightblue' for j in range(len(class_names))]\n",
    "    \n",
    "    axes[1, i].bar(range(len(class_names)), probs, color=colors)\n",
    "    axes[1, i].set_title(f'Predicted: {result[\"predicted_class\"]} ({result[\"confidence\"]:.2f})')\n",
    "    axes[1, i].set_xticks(range(len(class_names)))\n",
    "    axes[1, i].set_xticklabels([name.replace('_', '\\n') for name in class_names], rotation=0, fontsize=8)\n",
    "    axes[1, i].set_ylabel('Probability')\n",
    "    axes[1, i].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Explore Foundation Model Adapter\n",
    "\n",
    "Now let's explore the foundation model adapter capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create foundation model adapter (if CLIP is available)\n",
    "try:\n",
    "    adapter = create_foundation_adapter(\n",
    "        method=\"AD-CLIP\",\n",
    "        domain=\"materials\",  # PCBs are materials\n",
    "        rank=4,\n",
    "        alpha=32\n",
    "    )\n",
    "    \n",
    "    print(f\"Foundation adapter created successfully!\")\n",
    "    print(f\"Method: {adapter.config.method}\")\n",
    "    print(f\"Domain: {adapter.config.domain}\")\n",
    "    print(f\"Parameter efficiency: {adapter.efficiency_ratio:.4f}\")\n",
    "    print(f\"Trainable parameters: {adapter.trainable_parameters:,}\")\n",
    "    print(f\"Domain prompts: {len(adapter.config.domain_prompts)}\")\n",
    "    \n",
    "    for i, prompt in enumerate(adapter.config.domain_prompts[:3]):\n",
    "        print(f\"  {i+1}. {prompt}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Foundation adapter creation failed (likely missing CLIP): {e}\")\n",
    "    print(\"This is normal if you haven't installed the CLIP dependencies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Model Training Simulation\n",
    "\n",
    "Let's simulate a brief training session to show how the framework works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple training simulation\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def create_synthetic_dataset(num_samples=100):\n",
    "    \"\"\"Create synthetic training data\"\"\"\n",
    "    images = torch.randn(num_samples, 3, 224, 224)\n",
    "    labels = torch.randint(0, 5, (num_samples,))\n",
    "    return TensorDataset(images, labels)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = create_synthetic_dataset(200)\n",
    "val_dataset = create_synthetic_dataset(50)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Setup optimizer (only for trainable parameters)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [p for p in model.parameters() if p.requires_grad], \n",
    "    lr=1e-3, \n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# Quick training simulation (2 epochs)\n",
    "model.train()\n",
    "training_history = []\n",
    "\n",
    "for epoch in range(2):\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    training_history.append(avg_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}: Average Loss = {avg_loss:.4f}\")\n",
    "\n",
    "# Validation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"\\nValidation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Plot training curve\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(training_history, 'b-', label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Training simulation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Performance Analysis\n",
    "\n",
    "Let's analyze the model's performance characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Benchmark inference speed\n",
    "model.eval()\n",
    "sample_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# Warm up\n",
    "for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "        _ = model(sample_input)\n",
    "\n",
    "# Benchmark\n",
    "num_runs = 100\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    with torch.no_grad():\n",
    "        _ = model(sample_input)\n",
    "\n",
    "end_time = time.time()\n",
    "avg_inference_time = (end_time - start_time) / num_runs * 1000  # ms\n",
    "\n",
    "# Calculate model size\n",
    "def get_model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    return param_size / 1024 / 1024  # MB\n",
    "\n",
    "model_size_mb = get_model_size(model)\n",
    "\n",
    "# Performance summary\n",
    "print(\"📊 Performance Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,} ({(trainable_params/total_params)*100:.2f}%)\")\n",
    "print(f\"Parameter Efficiency: {efficiency:.4f}\")\n",
    "print(f\"Average Inference Time: {avg_inference_time:.2f} ms\")\n",
    "print(f\"Throughput: {1000/avg_inference_time:.1f} images/second\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Create performance visualization\n",
    "metrics = ['Model Size (MB)', 'Inference Time (ms)', 'Parameter Efficiency (%)']\n",
    "values = [model_size_mb, avg_inference_time, efficiency * 100]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Performance metrics bar chart\n",
    "ax1.bar(metrics, values, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "ax1.set_title('Model Performance Metrics')\n",
    "ax1.set_ylabel('Value')\n",
    "\n",
    "# Parameter distribution pie chart\n",
    "frozen_params = total_params - trainable_params\n",
    "ax2.pie([trainable_params, frozen_params], \n",
    "        labels=[f'Trainable\\n({trainable_params:,})', f'Frozen\\n({frozen_params:,})'],\n",
    "        colors=['lightcoral', 'lightblue'],\n",
    "        autopct='%1.1f%%')\n",
    "ax2.set_title('Parameter Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Tutorial completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. **Model Creation**: How to create enhanced PCB models with LoRA adaptation\n",
    "2. **Inference**: How to run predictions on PCB images\n",
    "3. **Visualization**: How to visualize results and model predictions\n",
    "4. **Foundation Adapters**: How to use CLIP-based adapters for domain-specific tasks\n",
    "5. **Training**: How the training process works (simulated)\n",
    "6. **Performance**: How to analyze model performance and efficiency\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore the [Advanced Tutorials](advanced_tutorials.ipynb)\n",
    "- Learn about [Hyperparameter Optimization](hyperparameter_optimization.ipynb)\n",
    "- Try the [Production Deployment Guide](../deployment/production.md)\n",
    "- Read about the [Research Methodology](../research/methodology.md)\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [API Reference](../api/core.rst)\n",
    "- [User Guide](../user_guide/foundation_models.md)\n",
    "- [GitHub Repository](https://github.com/soumyajitghosh/pcb-defect-detection)\n",
    "\n",
    "Happy detecting! 🔍"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
